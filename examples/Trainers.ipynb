{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Trainers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multi-GPU on a Single Node\n",
    "\n",
    "## (1) Torchrun and DDP\n",
    "```bash\n",
    "torchrun --standalone --nproc_per_node=gpu main.py --model Keci --trainer torchDDP --num_epochs 100 --embedding_dim 256 --q=1 --path_dataset_folder \"KGs/UMLS\"\n",
    "```\n",
    "```bash\n",
    "torchrun --standalone --nproc_per_node=gpu main.py --model Pykeen_QuatE --trainer torchDDP --num_epochs 100 --embedding_dim 256  --path_dataset_folder \"KGs/UMLS\" --pykeen_model_kwargs embedding_dim=16\n",
    "```\n",
    "## (2) Pytorch-Lightning with DDP\n",
    "```bash\n",
    "python main.py --trainer 'PL' --accelerator \"gpu\" --model Pykeen_QuatE --num_epochs 100 --embedding_dim 256  --path_dataset_folder \"KGs/UMLS\" --pykeen_model_kwargs embedding_dim=16\n",
    "```\n",
    "\n",
    "## Multi-GPU on Multi-Node\n",
    "\n",
    "## (1) Torchrun and DDP\n",
    "\n",
    "Execute the following command on the node 1.\n",
    "```bash\n",
    "torchrun --nnodes 2 --nproc_per_node=gpu  --node_rank 0 --rdzv_id 455 --rdzv_backend c10d --rdzv_endpoint=nebula main.py --model 'ComplEx' --embedding_dim 32 --num_epochs 100 --path_dataset_folder 'KGs/UMLS' --trainer torchDDP\n",
    "```\n",
    "Execute the following command on the node 2\n",
    "```bash\n",
    "torchrun --nnodes 2 --nproc_per_node=gpu  --node_rank 1 --rdzv_id 455 --rdzv_backend c10d --rdzv_endpoint=nebula main.py --model 'ComplEx' --embedding_dim 32 --num_epochs 100 --path_dataset_folder 'KGs/UMLS' --trainer torchDDP\n",
    "```\n",
    "\n",
    "Execute the following command on the node 1.\n",
    "```bash\n",
    "torchrun --nnodes 2 --nproc_per_node=gpu  --node_rank 0 --rdzv_id 455 --rdzv_backend c10d --rdzv_endpoint=felis main.py --model 'Pykeen_QuatE' --embedding_dim 32 --num_epochs 100 --path_dataset_folder 'KGs/UMLS' --trainer torchDDP\n",
    "```\n",
    "Execute the following command on the node 2\n",
    "```bash\n",
    "torchrun --nnodes 2 --nproc_per_node=gpu  --node_rank 1 --rdzv_id 455 --rdzv_backend c10d --rdzv_endpoint=felis main.py --model 'Pykeen_QuatE' --embedding_dim 32 --num_epochs 100 --path_dataset_folder 'KGs/UMLS' --trainer torchDDP\n",
    "```\n",
    "## (1) PL and DDP\n",
    "TODO:\n",
    "\n",
    "## Multi-GPU on Multi-Node with Model Parallel\n",
    "TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}